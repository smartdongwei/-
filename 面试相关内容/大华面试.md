## **1：前期准备：**

1：设计模式   

2：分布式   seta

3:  八股文 记住

4：spring的相关知识

### 1.1 网上找到的面试题

#### 1.1.1 ArrayList和Linkedlist区别？

(1) ArrayList的实现是基于数组，LinkedList的实现是基于双向链表。

(2) 对于随机访问，ArrayList优于LinkedList。

(3)对于插入和删除操作，LinkedList优于ArrayList

(4) LinkedList比ArrayList更占内存，因为LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素。

#### 1.1.2 hashmap实现原理？

**重要变量介绍：**

- `DEFAULT_INITIAL_CAPACITY` Table数组的初始化长度： `1 << 4``2^4=16`（为什么要是 2的n次方？）
- `MAXIMUM_CAPACITY` Table数组的最大长度： `1<<30``2^30=1073741824`
- `DEFAULT_LOAD_FACTOR` 负载因子：默认值为`0.75`。 当元素的总个数>当前数组的长度 * 负载因子。数组会进行扩容，扩容为原来的两倍（todo：为什么是两倍？）
- `TREEIFY_THRESHOLD` 链表树化阙值： 默认值为 `8` 。表示在一个node（Table）节点下的值的个数大于8时候，会将链表转换成为红黑树。
- `UNTREEIFY_THRESHOLD` 红黑树链化阙值： 默认值为 `6` 。 表示在进行扩容期间，单个Node节点下的红黑树节点的个数小于6时候，会将红黑树转化成为链表。
- `MIN_TREEIFY_CAPACITY = 64` 最小树化阈值，当Table所有元素超过改值，才会进行树化（为了防止前期阶段频繁扩容和树化过程冲突）。

​    HashMap是基于hash表实现的，而hash表底层是由**数组**加**链表**实现的。采⽤Entry数组来存储key-value对，每⼀个键值对组成了⼀个Entry实体，Entry类实际上是⼀个单向的链表结构，它具有Next指针，可以连接下⼀个Entry实体。 只是在JDK1.8中，链表⻓度⼤于8的时候，链表会转成红⿊树！

**1：HashMap的负载因子为什么是0.75？**

0.75的含义表达当HashMap的容量达到总容量的75%时HashMap会进行扩容。那HashMap的负载因子为什么要设置0.75呢？是有原因的，主要是从hash冲突和空间利用率两个方面来考量的。

而是根据一个数学公式推导出来的，被叫做**牛顿二项式**。公式算出来为0.693，而0.75是HashMap为了后面方便计算，0.75*size=整数，方便后面HashMap容量达到这个整数进行扩容。

**2.HashMap为什么每次扩容时都是2的指数倍？**

​    我们可以看到putVal时，会去判断table[i]的值为不为空，而数组下标i是怎么得出来的呢，是通过key的hash值&(n - 1)得到的数组下标i，n代表数组的长度。在计算下标时，能够更好的减少hash冲突。

**3.HashMap为什么要引入红黑树，而不是完全平衡二叉树？**

​    我们知道HashMap引入红黑树数据结构是为了解决链表O(n)的时间复杂度，达到一定条件时，链表就会转变红黑树。这里我们可以想一下，为什么HashMap引入的是红黑树，而不是完全平衡二叉树，完全平衡二叉树也可以解决链表O(n)的时间复杂度。这里就不概述红黑树和完全平衡二叉树的定义了，红黑树是一种相对平衡的二叉树，而完全平衡二叉树则是绝对平衡的。假设HashMap引入完全平衡二叉树，每当key插入进来时，完全平衡二叉树为了保持绝对的平衡，就会对树进行左旋，右旋操作来保持树的绝对平衡。这时插入的效率就会低下。而红黑树只需保持相对的平衡，并不会有过多的旋转操作，来使插入效率降低。完全平衡二叉树适合读多写少的场景，也就是get操作多，而put操作少。这时完全平衡二叉树的效率就会比红黑树的效率要高

**4：HashMap的转红黑树的阀值为什么是8？**

​    大概意思就是在负载因子为0.75的基础上，链表长度达到8个元素的概率为0.00000006，这个概率几乎很小了，这个概率是怎么算出来的呢，是通过一个叫泊松分布概率统计得出来的。

**5.HashMap达到什么条件下会转变成红黑树结构？**

​    链表节点必须达到8个 ，数组tab的长度必须大于等于64



#### 1.1.3 HashMap 为什么线程不安全？

##### 1.1.3.1 在1.7中的hashmap

​    死循环发生在HashMap的扩容函数中，根源在**transfer函数**中。在对table进行扩容到newTable后，需要将原来数据转移到newTable中，注意10-12行代码，这里可以看出在转移元素的过程中，使用的是头插法，也就是链表的顺序会翻转，这里也是形成死循环的关键点，会出现环形链表的情况。

##### 1.1.3.2 在1.8中的hashmap

​    如果没有hash碰撞则会直接插入元素。如果线程A和线程B同时进行put操作，刚好这两条不同的数据hash值一样，并且该位置数据为null，所以这线程A、B都会进入第6行代码中。假设一种情况，线程A进入后还未进行数据插入时挂起，而线程B正常执行，从而正常插入数据，然后线程A获取CPU时间片，此时线程A不用再进行hash判断了，问题出现：线程A会把线程B插入的数据给**覆盖**，发生线程不安全。

**总结**

首先HashMap是**线程不安全**的，其主要体现：

1.在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失。

2.在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。



##### 1.1.4 hashtable和concurrenthashmap的区别？

1. **底层数据结构：** JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；
2. **实现线程安全的方式（重要）**： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

##### 1.1.5 synchronized和ReentrantLock区别？



##### 1.1.6 序列化的使用方式以及情景

序列化：将java对象转换为字节序列化的过程

作用：可以将对象的字节序列化永久保存到硬盘上，通常存放在文件中；也可以将网络上传输对象的字节序列。

   java对象的序列化有两种方式：

- 是相应的对象实现了序列化接口Serializable，它的作用是标识这个对象时可序列化的。
- 实现序列化的第二种方式为实现接口Externalizable



##### 1.1.7 springBoot启动流程

**主要流程如下**

0.启动main方法开始

1.**初始化配置**：通过类加载器，（loadFactories）读取classpath下所有的spring.factories配置文件，创建一些初始配置对象；通知监听者应用程序启动开始，创建环境对象environment，用于读取环境配置 如 application.yml

2.**创建应用程序上下文**-createApplicationContext，创建 bean工厂对象

3.**刷新上下文（启动核心）**
3.1 配置工厂对象，包括上下文类加载器，对象发布处理器，beanFactoryPostProcessor
3.2 注册并实例化bean工厂发布处理器，并且调用这些处理器，对包扫描解析(主要是class文件)
3.3 注册并实例化bean发布处理器 beanPostProcessor
3.4 初始化一些与上下文有特别关系的bean对象（创建tomcat服务器）
3.5 实例化所有bean工厂缓存的bean对象（剩下的）
3.6 发布通知-通知上下文刷新完成（启动tomcat服务器）

4.**通知监听者-启动程序完成**

##### 1.1.8 JVM 线程dump 导出和分析

```css
jstack [-l] pid > xxx.log
```



##### 1.1.9 一个线程，run()里面写了一个while循环执行空语句，会占用CPU多少

操作系统中，CPU竞争有很多种策略。Unix系统使用的是时间片算法，而Windows则属于抢占式的。
       在时间片算法中，所有的进程排成一个队列。操作系统按照他们的顺序，给每个进程分配一段时间，即该进程允许运行的时间。如果在 时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。调度程 序所要做的就是维护一张就绪进程列表，，当进程用完它的时间片后，它被移到队列的末尾。
       所谓抢占式操作系统，就是说如果一个进程得到了 CPU 时间，除非它自己放弃使用 CPU ，否则将完全霸占 CPU 。因此可以看出，在抢 占式操作系统中，操作系统假设所有的进程都是“人品很好”的，会主动退出 CPU 。在抢占式操作系统中，假设有若干进程，操作系统会根据他们的优先级、饥饿时间（已经多长时间没有使用过 CPU 了），给他们算出一 个总的优先级来。操作系统就会把 CPU 交给总优先级最高的这个进程。当进程执行完毕或者自己主动挂起后，操作系统就会重新计算一 次所有进程的总优先级，然后再挑一个优先级最高的把 CPU 控制权交给他。
